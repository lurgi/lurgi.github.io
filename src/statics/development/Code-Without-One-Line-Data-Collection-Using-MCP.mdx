# 코드 한 줄 없이 데이터 수집 자동화? MCP로 해봤습니다

![Code-Without-One-Line-Data-Collection-Using-MCP](/statics/mcp.png)

저는 현재 요가 커뮤니티 플랫폼 ‘숨결’을 만들고 있습니다. 아직 시작한지 얼마 안된 따끈따뜻한 프로젝트에요.

[숨결](https://soomgyeol.vercel.app/)

웹 개발을 하면서 플랫폼형 서비스를 만들다 보면, 항상 부딪히는 고민이 하나 있습니다. 바로 **“초기 데이터를 어떻게 수집할 것인가?” 하는 문제**죠.

저도 예전에 Python으로 특정 블로그 글을 크롤링하는 코드를 짜본 적이 있었는데, 솔직히 말해 정말 번거롭고 귀찮은 작업이었습니다.

그래서 이번엔 다른 접근을 해봤어요. **“AI를 활용하면, 이 과정을 좀 더 효율적으로 자동화할 수 있지 않을까?”** 하는 생각이 들었거든요.

특히 시간은 부족한데, 작은 규모로 빠르게 시작하고 싶은 1인 개발자 입장에선 매번 수작업으로 데이터를 수집하는 건 너무 비효율적이잖아요.

그래서 이번엔 요즘 개발자들 사이에서 주목받고 있는 **‘MCP(Model Context Protocol)’ 방식을 활용해 자동화** **파이프라인을 설계**해봤습니다.

결과적으로는 Claude AI를 활용해 데이터를 자동으로 수집하고, DB에 저장하는 파이프라인을 성공적으로 구축할 수 있었어요.

---

## **🧩 MCP란?**

우선 MCP는 Anthropic에서 개발한 개방형 표준 프로토콜로, AI 모델이 외부 데이터 소스나 도구와 직접 상호작용할 수 있도록 해주는 표준화된 인터페이스를 제공합니다.

이를 통해 AI 시스템은 다양한 외부 자원과 보다 쉽게 연결될 수 있고, 기존에는 복잡하게 처리해야 했던 통합 작업도 훨씬 단순화됩니다.

쉽게 말하면, **AI가 직접 외부 툴이나 DB에 접근해서 사용할 수있게 해주는 기술**이라고 보면 됩니다.

---

## **🛠️ 파이프 라인에서 어떤 MCP 도구를 사용했을까요?**

저는 **Claude AI**를 활용해 MCP 기반의 데이터 수집 파이프라인을 구축했습니다.

아래 링크에서 MCP 관련 오픈소스 도구들을 확인할 수 있어요:

https://github.com/modelcontextprotocol/servers

그중 제가 실제로 사용한 MCP는 다음과 같습니다.

1. **Firecrawl MCP**

   → 웹사이트에서 요가 워크숍 데이터를 자동으로 수집할 수 있었습니다.

2. **Google Maps MCP**

   → 수집한 주소 정보를 **위도/경도 좌표로 변환**하여,

   **PostGIS 기반의 위치 서비스**에 활용했습니다.

3. **Supabase MCP**

   → 정제된 데이터를 **우리 서비스의 DB에 자동 저장**할 수 있었습니다.

이러한 도구들을 조합해,

**‘숨결’ 서비스의 요가 클래스 및 워크숍 데이터를 자동으로 수집하고 저장하는 완전한 파이프라인**을 구현할 수 있었어요.

---

## 🔁 자동화 파이프라인은 이렇게 구성했습니다

요가 클래스와 워크숍 정보를 자동으로 수집하기 위해, 총 6단계로 구성된 MCP 기반 파이프라인을 설계했습니다.

핵심은 *AI가 수작업 없이도 데이터를 수집, 가공, 저장할 수 있도록 만드는 것*이었습니다.

### 1단계: 워크숍 데이터 크롤링 (Firecrawl MCP)

Firecrawl MCP를 활용해 서울과 제주 지역의 요가 클래스 및 워크숍 정보를 크롤링합니다.

서울과 제주에서 정보를 수집하며, 강사 소개 / 후기 / 스케줄 / 이미지 등이 포함된 게시글만 선별합니다.

### 2단계: 위치 좌표 변환 (Google Maps MCP)

Google Maps MCP를 사용해 각 워크숍의 주소 정보를 위도/경도 좌표로 변환합니다.

이를 통해 위치 기반 서비스 개발에 필요한 PostGIS 지리 정보를 확보합니다.

### 3단계: 중복 데이터 필터링 (Supabase MCP)

크롤링한 데이터를 저장하기 전, Supabase의 Soomgyeol 프로젝트에서 최신 50개 데이터를 조회하여 제목, 주소, 좌표, 설명 유사도를 기준으로 중복 여부를 필터링합니다.

### 4단계: Description 필드 재구성 (Firecrawl MCP)

수집한 게시글의 내용을 기반으로 요약된 설명(description)을 재구성합니다.

글이 너무 길 경우 핵심 정보만 뽑아내며, Claude AI를 통해 내용을 명확하고 간결하게 정리합니다.

### 5단계: 워크숍 이미지 수집 (Firecrawl MCP)

해당 워크숍 또는 요가원과 관련된 공식 이미지를 Firecrawl로 찾아 추가합니다.

정확하지 않거나 워크숍과 직접적인 관련이 없는 이미지는 제외하며, 없을 경우 null로 처리합니다.

### 6단계: 데이터 Supabase 저장 (Supabase MCP)

정제된 최종 데이터를 Supabase의 workshop 테이블에 저장합니다.

이때 위치 정보는 ST_SetSRID(ST_MakePoint(lng, lat), 4326) 형식의 PostGIS geography 타입으로 저장하여, 지도 기반 기능에 활용할 수 있도록 설계합니다.

---

## **🚀 결과는 어땠을까요?**

**한번의 명령으로 서울과 제주 각 지역에서 총 5개의 워크숍 정보를 완전 자동화된 흐름으로 수집하고 등록**했습니다.

코드는 단 한 줄도 작성하지 않았고, 전 과정을 몇 번의 버튼 클릭으로 실행할 수 있었죠.

이제 이 파이프라인을 반복 실행하거나, 지역만 바꾸어 확장도 가능해졌습니다.

무엇보다도, 혼자 만드는 작은 서비스에 시간과 리소스를 아낄 수 있는 구조가 생겼다는 점에서 큰 의미가 있었습니다.

[숨결](https://soomgyeol.vercel.app/posts?type=workshop)

위 홈페이지에서 MCP로 만들어진 지역기반 데이터를 확인해보세요.

---

## ❗️유의할 점

이번 파이프라인은 여러 단계로 세분화되어 있는데, 그 이유는 Claude AI가 한 번에 긴 연산을 처리하는 데 다소 취약하기 때문입니다. 이 한계는 주로 **AI의 토큰 제한**(Token Limit)과 **기억력의 한계**(Context Window)에서 비롯됩니다.

Claude 3.7 기준으로는 최대 200,000토큰까지 입력을 처리할 수 있지만, **프롬프트와 입력 데이터, 작업 결과까지 포함하면 실제로 사용할 수 있는 여유는 더 줄어듭니다.** 특히 **MCP 기반 작업처럼 여러 도구와 연결된 데이터를 다루게 되면, 각 단계마다 전달되는 컨텍스트가 복잡하고 길어져 빠르게 토큰이 소진될 수 있습니다.**

예를 들어, 한 프롬프트에 크롤링 데이터, 주소 변환 결과, 중복 필터링 조건, 요약 대상 텍스트, 이미지 경로까지 포함되면 Claude가 그 모든 정보를 동시에 이해하고 판단해야 합니다. 이 과정에서 중요한 정보가 잘려나가거나, AI가 혼동해 엉뚱한 출력을 할 가능성도 생기죠. 또한 Claude는 문맥을 ‘이해’하기보다는 **통계적으로 다음 단어를 예측하는 구조**이기 때문에, 복잡한 상태를 장기적으로 유지하기 어렵습니다.

이러한 문제를 완화하기 위해 저는 프롬프트를 가능한 한 **짧고 명확하게 쪼개고**, 데이터도 **한 번에 5개씩만 처리하도록 제한**했습니다. 그래야 AI가 혼동하지 않고 안정적으로 작동하더라고요. 하지만 이 또한 임시방편일 뿐, **데이터의 신뢰도가 중요한 경우에는 중간중간 수작업 검증이나 보완 프로세스를 병행하는 것이 안전**하다고 생각합니다.

## 마무리하며.

이번 프로젝트를 통해 **MCP를 본격적으로 활용해보는 경험을 할 수 있었습니다.**

덕분에 앞으로는 다양한 MCP 서버를 통해 그동안 번거롭게 느껴졌던 작업들을 훨씬 수월하게 처리할 수 있겠다는 확신이 들었어요.

특히, MCP의 구조 덕분에 **노코드나 로우코드 방식으로도 충분히 유용한 서비스를 만들어낼 수 있겠다는 가능성**을 확인할 수 있었죠.

앞으로도 MCP를 더 자주, 더 깊이 활용해보며 다양한 실전 경험을 쌓아가고자 합니다.
